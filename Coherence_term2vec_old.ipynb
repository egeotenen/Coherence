{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "218724d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: networkx in /Users/eotenen/mambaforge/lib/python3.10/site-packages (3.0)\n",
      "Requirement already satisfied: gensim in /Users/eotenen/mambaforge/lib/python3.10/site-packages (4.3.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/eotenen/mambaforge/lib/python3.10/site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/eotenen/mambaforge/lib/python3.10/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Users/eotenen/mambaforge/lib/python3.10/site-packages (from gensim) (1.24.2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "!pip install networkx\n",
    "import networkx as nx\n",
    "import re\n",
    "import scipy.spatial.distance as sp\n",
    "\n",
    "!pip install gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec689c6",
   "metadata": {},
   "source": [
    "### 1.Define Model \\ Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66822faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOC2VEC\n",
    "\n",
    "tokenized_doc = []\n",
    "for d in sentences:\n",
    "    tokenized_doc.append(word_tokenize(d.lower()))\n",
    "\n",
    "\n",
    "tagged_data = [TaggedDocument(d, [i]) for i, d in enumerate(tokenized_doc)]\n",
    "\n",
    "## Train doc2vec model\n",
    "model = Doc2Vec(tagged_data, vector_size=20, window=2, min_count=1, workers=4, epochs = 100)\n",
    "# Save trained doc2vec model\n",
    "model.save(\"test_doc2vec.model\")\n",
    "## Load saved doc2vec model\n",
    "model= Doc2Vec.load(\"test_doc2vec.model\")\n",
    "## Print model vocabulary\n",
    "model.wv\n",
    "\n",
    "for sentence in sentences:\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "   \n",
    "    words = sentence.split(\" \")\n",
    "    v = [word for word in words]\n",
    "    [model.wv.n_similarity(v1,v2)  for v1, v2 in zip(v,v[1:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dde9aa",
   "metadata": {},
   "source": [
    "#### 1.1. Get Sentences Into DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "49a4e1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentences = [\"Under the Biden's presidency, the gas prices have decreased to their pre-Russian invasion of Ukraine levels.\",\n",
    "\"Wisconsin's archaic abortion ban is older than 20 states.\",\n",
    "\"The USA has a gun homicide rate 26 times higher than our peers.\",\n",
    "\"86% of Americans and 82% of gun owners support requiring all gun buyers to pass a background check.\",\n",
    "\"It's just crazy': 12 major cities hit all-time homicide records\",\n",
    "\"Biden says he released 22 years of my tax returns but Donald Trump hasn’t released a single one.\",\n",
    "\"When the New York State Senate voted to legalize abortion in 1970, 12 Republican senators voted in favor of it.\",\n",
    "\"Each of the pro-life governors up for election won in November.\",\n",
    "\"The Trump administration worked to free 5,000 prisoners of Taliban.\",\n",
    "\"Biden reduced the Strategic Petroleum Reserves of the United States to their lowest level since 1984. The reserve used to had more than 600 million barrels.\",\n",
    "\"GOP senators introduce bill designating Mexican drug cartels as terror organizations\",\n",
    "\"The inflation is costing American families more than $250 per month under Biden's policies.\",\n",
    "\"Donald Trump and his campaign donated food and supplies to Hurricane Matthew victims\",\n",
    "\"The average family in America pays more money for to their local hospital than to the IRS.\",\n",
    "\"Joe Biden aggrees transgender women aren't real women! He told a transgender women you will never be a realm woman.\",\n",
    "\"A photo shows Barack Obama dressed up as Baphomet (Lucifer).\",\n",
    "\"Biden didn’t win in Arizona. He lost in Arizona based on the forensic audit.\",\n",
    "\"It is known that no candidate has ever won both Florida and Ohio and lost, but Trump did.\",\n",
    "\"There are 63 million abortions a year in this country.\",\n",
    "\"A new study finds only 6% of the people actually died from COVID. The others died from other reasons.\",\n",
    "\"Video shows Joe Biden putting a Medal of Honor on a Vietnam War veteran backward.\",\n",
    "\"83 percent of the benefits from Republican tax reform in 2017 went to the wealthiest 1 percent.\",\n",
    "\"There is an increase in Social Security checks for seniors for the first time in 10 years under president Biden.\",\n",
    "\"Donald Trump has not apologized for comments caught on tape by Access Hollywood.\",\n",
    "\"When Trump won, we had the lowest voter turnout in 20 years.\",\n",
    "\"US spend twice as much per capita on health care as any other nation on Earth.\",\n",
    "\"Last year, Biden said they funded 700,000 major construction projects.\",\n",
    "\"Trump’s tax plan was completely focused on the wealthy and the powerful - not the middle class.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "26ce93ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "67f6c884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cc6f35",
   "metadata": {},
   "source": [
    "### 1.2. Get Similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23758dec",
   "metadata": {},
   "source": [
    "#### 1.2.1. Make them Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ab847dcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555], 1: [0.33759552, 0.882059, 0.882059, 0.33759555, 0.0, 0.0, 0.0, 0.0], 2: [0.4849517, 1.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 3: [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0], 4: [0.99999994, 0.5401927, 0.0, 0.0, 0.5401927, 0.8032929, 0.8592872, 0.0, 0.0], 5: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0], 6: [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0], 7: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 8: [1.0, 0.8294905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 9: [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0], 10: [0.0, 0.67274845, 0.0, 0.0, 0.8268447, 0.0, 0.0, 0.9269297, 0.4849517, 0.7224728], 11: [0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], 12: [0.5169574, 0.5169574, 0.33759555, 0.33759555, 0.882059, 0.0, 0.0, 0.33759555, 0.26141003, 0.5169574, 0.7779298, 0.8048985], 13: [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003], 14: [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0], 15: [0.5169574, 0.26141003, 0.33759555, 1.0, 0.33759555, 0.0, 0.0, 0.76983505, 0.0], 16: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108], 17: [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0], 18: [0.5169574, 0.0, 0.0, 0.0, 0.8268447, 1.0, 0.0, 0.0, 0.8032929], 19: [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176], 20: [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059], 21: [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0], 22: [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 23: [0.5169574, 0.4849517, 0.4849517, 0.5169574, 0.0, 0.0, 0.7649056, 0.0, 0.0, 0.0, 0.0, 0.0], 24: [0.0, 0.0, 0.0, 0.0, 0.5169574, 0.8032929, 0.8032929, 1.0, 0.0, 0.0, 0.0], 25: [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0], 26: [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345], 27: [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]}\n"
     ]
    }
   ],
   "source": [
    "mydict={}\n",
    "for i,sentence in enumerate(list_sentences):\n",
    "    try:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "        words = sentence.split(\" \")\n",
    "        similarities = [model.wv.n_similarity(v1, v2) for v1, v2 in zip(words, words[1:])]\n",
    "        pairs = [(v1, v2) for v1, v2 in zip(words, words[1:])]      \n",
    "    except:\n",
    "        pass\n",
    "    for a in range(len(similarities)):\n",
    "        \" Get them into dictionary sentence no: similarities\"\n",
    "        mydict[i]=similarities\n",
    "print(mydict)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "758fcbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "[0.33759552, 0.882059, 0.882059, 0.33759555, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.4849517, 1.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "[0.99999994, 0.5401927, 0.0, 0.0, 0.5401927, 0.8032929, 0.8592872, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[1.0, 0.8294905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.67274845, 0.0, 0.0, 0.8268447, 0.0, 0.0, 0.9269297, 0.4849517, 0.7224728]\n",
      "[0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "[0.5169574, 0.5169574, 0.33759555, 0.33759555, 0.882059, 0.0, 0.0, 0.33759555, 0.26141003, 0.5169574, 0.7779298, 0.8048985]\n",
      "[0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "[0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "[0.5169574, 0.26141003, 0.33759555, 1.0, 0.33759555, 0.0, 0.0, 0.76983505, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108]\n",
      "[0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "[0.5169574, 0.0, 0.0, 0.0, 0.8268447, 1.0, 0.0, 0.0, 0.8032929]\n",
      "[0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "[0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "[0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.5169574, 0.4849517, 0.4849517, 0.5169574, 0.0, 0.0, 0.7649056, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.5169574, 0.8032929, 0.8032929, 1.0, 0.0, 0.0, 0.0]\n",
      "[1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "[0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "[0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n"
     ]
    }
   ],
   "source": [
    "for key in mydict:\n",
    "    print(mydict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3973566f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "8\n",
      "12\n",
      "17\n",
      "9\n",
      "17\n",
      "19\n",
      "10\n",
      "9\n",
      "25\n",
      "10\n",
      "13\n",
      "12\n",
      "16\n",
      "19\n",
      "9\n",
      "13\n",
      "17\n",
      "9\n",
      "18\n",
      "14\n",
      "16\n",
      "19\n",
      "12\n",
      "11\n",
      "15\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for key in mydict:\n",
    "     print(len(mydict[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdde176",
   "metadata": {},
   "source": [
    "#### 2.3. Calculate Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "edf83c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_sims =[]\n",
    "for key in mydict:\n",
    "    doc2vec_sim = (np.mean(mydict[key]))\n",
    "    doc2vec_sims.append(doc2vec_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bf4cdb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doc2vec_sims'] = doc2vec_sims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7c47b6",
   "metadata": {},
   "source": [
    "### 3. Save the Similarity Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "81603ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('similarities.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd8463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d0dc2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2723c6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0836f796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda5b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97c6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc7aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f54fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac4c91dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "0 [0.0, 0.26141003, 1.0, 0.26141003, 0.4849517, 0.7924363, 0.33759555, 0.84166795, 0.4849517, 1.0, 0.42438173, 0.97226405, 0.0, 0.0, 0.33759555]\n",
      "1 [0.33759552, 0.882059, 0.882059, 0.33759555, 0.0, 0.0, 0.0, 0.0]\n",
      "1 [0.33759552, 0.882059, 0.882059, 0.33759555, 0.0, 0.0, 0.0, 0.0]\n",
      "1 [0.33759552, 0.882059, 0.882059, 0.33759555, 0.0, 0.0, 0.0, 0.0]\n",
      "1 [0.33759552, 0.882059, 0.882059, 0.33759555, 0.0, 0.0, 0.0, 0.0]\n",
      "1 [0.33759552, 0.882059, 0.882059, 0.33759555, 0.0, 0.0, 0.0, 0.0]\n",
      "1 [0.33759552, 0.882059, 0.882059, 0.33759555, 0.0, 0.0, 0.0, 0.0]\n",
      "1 [0.33759552, 0.882059, 0.882059, 0.33759555, 0.0, 0.0, 0.0, 0.0]\n",
      "1 [0.33759552, 0.882059, 0.882059, 0.33759555, 0.0, 0.0, 0.0, 0.0]\n",
      "2 [0.4849517, 1.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2 [0.4849517, 1.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2 [0.4849517, 1.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2 [0.4849517, 1.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2 [0.4849517, 1.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2 [0.4849517, 1.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2 [0.4849517, 1.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2 [0.4849517, 1.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2 [0.4849517, 1.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2 [0.4849517, 1.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2 [0.4849517, 1.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2 [0.4849517, 1.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "3 [0.0, 0.0, 0.9401378, 0.0, 0.0, 0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.26141003, 0.42438176, 0.69202626, 1.0, 0.0]\n",
      "4 [0.99999994, 0.5401927, 0.0, 0.0, 0.5401927, 0.8032929, 0.8592872, 0.0, 0.0]\n",
      "4 [0.99999994, 0.5401927, 0.0, 0.0, 0.5401927, 0.8032929, 0.8592872, 0.0, 0.0]\n",
      "4 [0.99999994, 0.5401927, 0.0, 0.0, 0.5401927, 0.8032929, 0.8592872, 0.0, 0.0]\n",
      "4 [0.99999994, 0.5401927, 0.0, 0.0, 0.5401927, 0.8032929, 0.8592872, 0.0, 0.0]\n",
      "4 [0.99999994, 0.5401927, 0.0, 0.0, 0.5401927, 0.8032929, 0.8592872, 0.0, 0.0]\n",
      "4 [0.99999994, 0.5401927, 0.0, 0.0, 0.5401927, 0.8032929, 0.8592872, 0.0, 0.0]\n",
      "4 [0.99999994, 0.5401927, 0.0, 0.0, 0.5401927, 0.8032929, 0.8592872, 0.0, 0.0]\n",
      "4 [0.99999994, 0.5401927, 0.0, 0.0, 0.5401927, 0.8032929, 0.8592872, 0.0, 0.0]\n",
      "4 [0.99999994, 0.5401927, 0.0, 0.0, 0.5401927, 0.8032929, 0.8592872, 0.0, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "5 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7649056, 0.8032929, 0.5169574, 0.5169574, 0.7533626, 0.88003224, 0.84166795, 0.33759555, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "6 [0.0, 0.0, 0.0, 0.0, 0.98015374, 0.7776745, 1.0, 0.5169574, 0.882059, 0.0, 0.0, 0.0, 0.0, 0.733976, 0.67274845, 0.0, 0.0, 0.0, 0.0]\n",
      "7 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "7 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "7 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "7 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "7 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "7 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "7 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "7 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "7 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "7 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "8 [1.0, 0.8294905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "8 [1.0, 0.8294905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "8 [1.0, 0.8294905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "8 [1.0, 0.8294905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "8 [1.0, 0.8294905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "8 [1.0, 0.8294905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "8 [1.0, 0.8294905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "8 [1.0, 0.8294905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "8 [1.0, 0.8294905, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "9 [0.0, 0.0, 0.8868668, 0.8868668, 0.26141003, 0.0, 0.0, 1.0, 0.80353093, 0.80353093, 1.0, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.26141003, 1.0, 0.26141003, 0.5169574, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "10 [0.0, 0.67274845, 0.0, 0.0, 0.8268447, 0.0, 0.0, 0.9269297, 0.4849517, 0.7224728]\n",
      "10 [0.0, 0.67274845, 0.0, 0.0, 0.8268447, 0.0, 0.0, 0.9269297, 0.4849517, 0.7224728]\n",
      "10 [0.0, 0.67274845, 0.0, 0.0, 0.8268447, 0.0, 0.0, 0.9269297, 0.4849517, 0.7224728]\n",
      "10 [0.0, 0.67274845, 0.0, 0.0, 0.8268447, 0.0, 0.0, 0.9269297, 0.4849517, 0.7224728]\n",
      "10 [0.0, 0.67274845, 0.0, 0.0, 0.8268447, 0.0, 0.0, 0.9269297, 0.4849517, 0.7224728]\n",
      "10 [0.0, 0.67274845, 0.0, 0.0, 0.8268447, 0.0, 0.0, 0.9269297, 0.4849517, 0.7224728]\n",
      "10 [0.0, 0.67274845, 0.0, 0.0, 0.8268447, 0.0, 0.0, 0.9269297, 0.4849517, 0.7224728]\n",
      "10 [0.0, 0.67274845, 0.0, 0.0, 0.8268447, 0.0, 0.0, 0.9269297, 0.4849517, 0.7224728]\n",
      "10 [0.0, 0.67274845, 0.0, 0.0, 0.8268447, 0.0, 0.0, 0.9269297, 0.4849517, 0.7224728]\n",
      "10 [0.0, 0.67274845, 0.0, 0.0, 0.8268447, 0.0, 0.0, 0.9269297, 0.4849517, 0.7224728]\n",
      "11 [0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "11 [0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "11 [0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "11 [0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "11 [0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "11 [0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "11 [0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "11 [0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "11 [0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "11 [0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "11 [0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "11 [0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "11 [0.8592872, 0.34560108, 0.7848633, 0.5401927, 0.84166795, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "12 [0.5169574, 0.5169574, 0.33759555, 0.33759555, 0.882059, 0.0, 0.0, 0.33759555, 0.26141003, 0.5169574, 0.7779298, 0.8048985]\n",
      "12 [0.5169574, 0.5169574, 0.33759555, 0.33759555, 0.882059, 0.0, 0.0, 0.33759555, 0.26141003, 0.5169574, 0.7779298, 0.8048985]\n",
      "12 [0.5169574, 0.5169574, 0.33759555, 0.33759555, 0.882059, 0.0, 0.0, 0.33759555, 0.26141003, 0.5169574, 0.7779298, 0.8048985]\n",
      "12 [0.5169574, 0.5169574, 0.33759555, 0.33759555, 0.882059, 0.0, 0.0, 0.33759555, 0.26141003, 0.5169574, 0.7779298, 0.8048985]\n",
      "12 [0.5169574, 0.5169574, 0.33759555, 0.33759555, 0.882059, 0.0, 0.0, 0.33759555, 0.26141003, 0.5169574, 0.7779298, 0.8048985]\n",
      "12 [0.5169574, 0.5169574, 0.33759555, 0.33759555, 0.882059, 0.0, 0.0, 0.33759555, 0.26141003, 0.5169574, 0.7779298, 0.8048985]\n",
      "12 [0.5169574, 0.5169574, 0.33759555, 0.33759555, 0.882059, 0.0, 0.0, 0.33759555, 0.26141003, 0.5169574, 0.7779298, 0.8048985]\n",
      "12 [0.5169574, 0.5169574, 0.33759555, 0.33759555, 0.882059, 0.0, 0.0, 0.33759555, 0.26141003, 0.5169574, 0.7779298, 0.8048985]\n",
      "12 [0.5169574, 0.5169574, 0.33759555, 0.33759555, 0.882059, 0.0, 0.0, 0.33759555, 0.26141003, 0.5169574, 0.7779298, 0.8048985]\n",
      "12 [0.5169574, 0.5169574, 0.33759555, 0.33759555, 0.882059, 0.0, 0.0, 0.33759555, 0.26141003, 0.5169574, 0.7779298, 0.8048985]\n",
      "12 [0.5169574, 0.5169574, 0.33759555, 0.33759555, 0.882059, 0.0, 0.0, 0.33759555, 0.26141003, 0.5169574, 0.7779298, 0.8048985]\n",
      "12 [0.5169574, 0.5169574, 0.33759555, 0.33759555, 0.882059, 0.0, 0.0, 0.33759555, 0.26141003, 0.5169574, 0.7779298, 0.8048985]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "13 [0.5169574, 1.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5169574, 0.8268447, 0.92208904, 0.8592872, 1.0, 0.26141003]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "14 [0.0, 0.0, 0.9269297, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.5169574, 0.8268447, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "15 [0.5169574, 0.26141003, 0.33759555, 1.0, 0.33759555, 0.0, 0.0, 0.76983505, 0.0]\n",
      "15 [0.5169574, 0.26141003, 0.33759555, 1.0, 0.33759555, 0.0, 0.0, 0.76983505, 0.0]\n",
      "15 [0.5169574, 0.26141003, 0.33759555, 1.0, 0.33759555, 0.0, 0.0, 0.76983505, 0.0]\n",
      "15 [0.5169574, 0.26141003, 0.33759555, 1.0, 0.33759555, 0.0, 0.0, 0.76983505, 0.0]\n",
      "15 [0.5169574, 0.26141003, 0.33759555, 1.0, 0.33759555, 0.0, 0.0, 0.76983505, 0.0]\n",
      "15 [0.5169574, 0.26141003, 0.33759555, 1.0, 0.33759555, 0.0, 0.0, 0.76983505, 0.0]\n",
      "15 [0.5169574, 0.26141003, 0.33759555, 1.0, 0.33759555, 0.0, 0.0, 0.76983505, 0.0]\n",
      "15 [0.5169574, 0.26141003, 0.33759555, 1.0, 0.33759555, 0.0, 0.0, 0.76983505, 0.0]\n",
      "15 [0.5169574, 0.26141003, 0.33759555, 1.0, 0.33759555, 0.0, 0.0, 0.76983505, 0.0]\n",
      "16 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108]\n",
      "16 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108]\n",
      "16 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108]\n",
      "16 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108]\n",
      "16 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108]\n",
      "16 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108]\n",
      "16 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108]\n",
      "16 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108]\n",
      "16 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108]\n",
      "16 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108]\n",
      "16 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108]\n",
      "16 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108]\n",
      "16 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.84166795, 0.0, 0.0, 0.26141003, 0.34560108]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "17 [0.26141003, 0.0, 0.0, 0.0, 0.0, 0.81965834, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.5401927, 0.8032929, 1.0, 0.0]\n",
      "18 [0.5169574, 0.0, 0.0, 0.0, 0.8268447, 1.0, 0.0, 0.0, 0.8032929]\n",
      "18 [0.5169574, 0.0, 0.0, 0.0, 0.8268447, 1.0, 0.0, 0.0, 0.8032929]\n",
      "18 [0.5169574, 0.0, 0.0, 0.0, 0.8268447, 1.0, 0.0, 0.0, 0.8032929]\n",
      "18 [0.5169574, 0.0, 0.0, 0.0, 0.8268447, 1.0, 0.0, 0.0, 0.8032929]\n",
      "18 [0.5169574, 0.0, 0.0, 0.0, 0.8268447, 1.0, 0.0, 0.0, 0.8032929]\n",
      "18 [0.5169574, 0.0, 0.0, 0.0, 0.8268447, 1.0, 0.0, 0.0, 0.8032929]\n",
      "18 [0.5169574, 0.0, 0.0, 0.0, 0.8268447, 1.0, 0.0, 0.0, 0.8032929]\n",
      "18 [0.5169574, 0.0, 0.0, 0.0, 0.8268447, 1.0, 0.0, 0.0, 0.8032929]\n",
      "18 [0.5169574, 0.0, 0.0, 0.0, 0.8268447, 1.0, 0.0, 0.0, 0.8032929]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "19 [0.0, 0.0, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.0, 0.42438176]\n",
      "20 [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "20 [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "20 [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "20 [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "20 [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "20 [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "20 [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "20 [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "20 [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "20 [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "20 [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "20 [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "20 [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "20 [0.0, 0.0, 0.0, 0.0, 0.5169574, 1.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.882059, 0.882059, 0.882059]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "21 [0.0, 0.0, 0.0, 0.8032929, 0.0, 0.0, 0.882059, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8868668, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "22 [0.26141003, 0.33759555, 0.84166795, 0.0, 0.0, 0.80030024, 0.7848633, 0.0, 0.0, 0.0, 0.0, 0.8032929, 0.8032929, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "23 [0.5169574, 0.4849517, 0.4849517, 0.5169574, 0.0, 0.0, 0.7649056, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "23 [0.5169574, 0.4849517, 0.4849517, 0.5169574, 0.0, 0.0, 0.7649056, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "23 [0.5169574, 0.4849517, 0.4849517, 0.5169574, 0.0, 0.0, 0.7649056, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "23 [0.5169574, 0.4849517, 0.4849517, 0.5169574, 0.0, 0.0, 0.7649056, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "23 [0.5169574, 0.4849517, 0.4849517, 0.5169574, 0.0, 0.0, 0.7649056, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "23 [0.5169574, 0.4849517, 0.4849517, 0.5169574, 0.0, 0.0, 0.7649056, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "23 [0.5169574, 0.4849517, 0.4849517, 0.5169574, 0.0, 0.0, 0.7649056, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "23 [0.5169574, 0.4849517, 0.4849517, 0.5169574, 0.0, 0.0, 0.7649056, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "23 [0.5169574, 0.4849517, 0.4849517, 0.5169574, 0.0, 0.0, 0.7649056, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "23 [0.5169574, 0.4849517, 0.4849517, 0.5169574, 0.0, 0.0, 0.7649056, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "23 [0.5169574, 0.4849517, 0.4849517, 0.5169574, 0.0, 0.0, 0.7649056, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "23 [0.5169574, 0.4849517, 0.4849517, 0.5169574, 0.0, 0.0, 0.7649056, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "24 [0.0, 0.0, 0.0, 0.0, 0.5169574, 0.8032929, 0.8032929, 1.0, 0.0, 0.0, 0.0]\n",
      "24 [0.0, 0.0, 0.0, 0.0, 0.5169574, 0.8032929, 0.8032929, 1.0, 0.0, 0.0, 0.0]\n",
      "24 [0.0, 0.0, 0.0, 0.0, 0.5169574, 0.8032929, 0.8032929, 1.0, 0.0, 0.0, 0.0]\n",
      "24 [0.0, 0.0, 0.0, 0.0, 0.5169574, 0.8032929, 0.8032929, 1.0, 0.0, 0.0, 0.0]\n",
      "24 [0.0, 0.0, 0.0, 0.0, 0.5169574, 0.8032929, 0.8032929, 1.0, 0.0, 0.0, 0.0]\n",
      "24 [0.0, 0.0, 0.0, 0.0, 0.5169574, 0.8032929, 0.8032929, 1.0, 0.0, 0.0, 0.0]\n",
      "24 [0.0, 0.0, 0.0, 0.0, 0.5169574, 0.8032929, 0.8032929, 1.0, 0.0, 0.0, 0.0]\n",
      "24 [0.0, 0.0, 0.0, 0.0, 0.5169574, 0.8032929, 0.8032929, 1.0, 0.0, 0.0, 0.0]\n",
      "24 [0.0, 0.0, 0.0, 0.0, 0.5169574, 0.8032929, 0.8032929, 1.0, 0.0, 0.0, 0.0]\n",
      "24 [0.0, 0.0, 0.0, 0.0, 0.5169574, 0.8032929, 0.8032929, 1.0, 0.0, 0.0, 0.0]\n",
      "24 [0.0, 0.0, 0.0, 0.0, 0.5169574, 0.8032929, 0.8032929, 1.0, 0.0, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "25 [1.0, 0.26141003, 0.4849517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.882059, 0.84166795, 0.84166795, 0.5169574, 0.8592872, 0.0, 0.0]\n",
      "26 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "26 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "26 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "26 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "26 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "26 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "26 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "26 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "26 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "27 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "27 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "27 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "27 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "27 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "27 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "27 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "27 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n",
      "27 [0.8268447, 0.0, 0.0, 0.4849517, 0.0, 0.0, 0.0, 0.5578812, 0.96962345]\n"
     ]
    }
   ],
   "source": [
    "for i,sentence in enumerate(df.text):\n",
    "    try:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "        words = sentence.split(\" \")\n",
    "        similarities = [model.wv.n_similarity(v1, v2) for v1, v2 in zip(words, words[1:])]\n",
    "        pairs = [(v1, v2) for v1, v2 in zip(words, words[1:])]      \n",
    "    except:\n",
    "        pass\n",
    "    for a in range(len(similarities)):\n",
    "            print(i,similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5174a4",
   "metadata": {},
   "source": [
    "### Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "02e05571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n",
      "Model Saved\n",
      "V1_infer [ 0.00226285  0.00454831 -0.00910156 -0.01735898  0.02206396 -0.01620167\n",
      " -0.01587807 -0.02946209  0.00692936  0.01063237  0.02231291  0.02321248\n",
      " -0.02531318 -0.02330405  0.01226876 -0.01983754  0.00979437  0.01245933\n",
      " -0.00558981 -0.01925103]\n",
      "[('2', 0.9122262597084045), ('0', 0.7618080973625183), ('3', 0.7178300023078918)]\n",
      "[-0.4464615   0.05181082 -0.46369314  0.0706271   0.6003256  -0.6622851\n",
      " -0.6252563  -0.6537112   0.07582504 -0.7323634   0.2951613   0.5026427\n",
      " -0.7469875  -0.7266919  -0.28869343  0.07489646  0.00168609 -0.35149062\n",
      " -0.6598793   0.21526803]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eotenen/mambaforge/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:42: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "/Users/eotenen/mambaforge/envs/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:47: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n"
     ]
    }
   ],
   "source": [
    "data = [\"I love machine learning. Its awesome.\",\n",
    "        \"I love coding in python\",\n",
    "        \"I love building chatbots\",\n",
    "        \"they chat amagingly well\"]\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(data)]\n",
    "\n",
    "max_epochs = 100\n",
    "vector_size = 20\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(vector_size=vector_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.epochs)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v.model\")\n",
    "print(\"Model Saved\")\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model= Doc2Vec.load(\"d2v.model\")\n",
    "#to find the vector of a document which is not in training data\n",
    "test_data = word_tokenize(\"I love chatbots\".lower())\n",
    "v1 = model.infer_vector(test_data)\n",
    "print(\"V1_infer\", v1)\n",
    "\n",
    "# to find most similar doc using tags\n",
    "similar_doc = model.docvecs.most_similar('1')\n",
    "print(similar_doc)\n",
    "\n",
    "\n",
    "# to find vector of doc in training data using tags or in other words, printing the vector of document at index 1 in training data\n",
    "print(model.docvecs['1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85323f49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for sentence in sentences:\n",
    "    words = sentence.split(\" \")\n",
    "    words = [word.lower() for word in words]\n",
    "    try:\n",
    "        v = [model[word] for word in words]\n",
    "        vd = [sp.euclidean(v1,v2) for v1, v2 in zip(v,v[1:])]\n",
    "        print(sentence, np.std(vd))\n",
    "    except:\n",
    "        KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d25c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"When the New York State Senate voted to legalize abortion in 1970, 12 Republican senators voted in favor of it\",\n",
    "            \"Gas prices have decreased to their pre-Russian invasion of Ukraine levels\",\n",
    "             \"Wisconsin's archaic abortion ban is older than 20 states\",\n",
    "             \"The USA has a gun homicide rate 26 times higher than our peers.\",\n",
    "             \"86% of Americans and 82% of gun owners support requiring all gun buyers to pass a background check\",\n",
    "             \"Joe Biden’s $36 billion for a union pension fund is the largest private pension bailout in American history\",\n",
    "             \"Biden says he released 22 years of my tax returns but Donald Trump hasn’t released a single one\"]\n",
    "\n",
    " \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "def preprocess(text):\n",
    "    # Define the text to preprocess\n",
    "    # Convert the text to lowercase\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "\n",
    "    # Lemmatize the tokens\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "\n",
    "    # Print the final list of preprocessed and tokenized words\n",
    "    return(lemmatized_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10be9673",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1970,'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m words \u001b[38;5;241m=\u001b[39m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m words \u001b[38;5;241m=\u001b[39m [word\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m---> 17\u001b[0m v \u001b[38;5;241m=\u001b[39m [term2vec[word] \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[1;32m     18\u001b[0m vd \u001b[38;5;241m=\u001b[39m [sp\u001b[38;5;241m.\u001b[39meuclidean(v1,v2) \u001b[38;5;28;01mfor\u001b[39;00m v1, v2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(v,v[\u001b[38;5;241m1\u001b[39m:])]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(sentence, np\u001b[38;5;241m.\u001b[39mstd(vd))\n",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m words \u001b[38;5;241m=\u001b[39m sentence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m words \u001b[38;5;241m=\u001b[39m [word\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m---> 17\u001b[0m v \u001b[38;5;241m=\u001b[39m [\u001b[43mterm2vec\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[1;32m     18\u001b[0m vd \u001b[38;5;241m=\u001b[39m [sp\u001b[38;5;241m.\u001b[39meuclidean(v1,v2) \u001b[38;5;28;01mfor\u001b[39;00m v1, v2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(v,v[\u001b[38;5;241m1\u001b[39m:])]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(sentence, np\u001b[38;5;241m.\u001b[39mstd(vd))\n",
      "\u001b[0;31mKeyError\u001b[0m: '1970,'"
     ]
    }
   ],
   "source": [
    "for line in d:\n",
    "        l = line.strip('\\n')\n",
    "        vals = l.split(\" \")\n",
    "        term2vec[vals[0]] = np.asfarray(vals[1:])\n",
    "\n",
    "sentences = [\"When the New York State Senate voted to legalize abortion in 1970, 12 Republican senators voted in favor of it\",\n",
    "            \"Gas prices have decreased to their pre-Russian invasion of Ukraine levels\",\n",
    "             \"Wisconsin's archaic abortion ban is older than 20 states\",\n",
    "             \"The USA has a gun homicide rate 26 times higher than our peers.\",\n",
    "             \"86% of Americans and 82% of gun owners support requiring all gun buyers to pass a background check\",\n",
    "             \"Joe Biden’s $36 billion for a union pension fund is the largest private pension bailout in American history\",\n",
    "             \"Biden says he released 22 years of my tax returns but Donald Trump hasn’t released a single one\"]\n",
    "             \n",
    "for sentence in sentences:\n",
    "    words = sentence.split(\" \")\n",
    "    words = [word.lower() for word in words]\n",
    "    v = [term2vec[word] for word in words]\n",
    "    vd = [sp.euclidean(v1,v2) for v1, v2 in zip(v,v[1:])]\n",
    "    print(sentence, np.std(vd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5cd3d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = gensim.downloader.load( 'word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52583b4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-ea7d40f59b83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvector_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mvector_object\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_to_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mall_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "all_vectors = []\n",
    "for index, vector in enumerate(model.wv.vectors):\n",
    "    vector_object = {}\n",
    "\n",
    "    vector_object[list(model.wv.key_to_index())[index]] = vector\n",
    "    all_vectors.append(vector_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f6d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# Load vectors directly from the file\n",
    "\n",
    "# Access vectors for specific words with a keyed lookup:\n",
    "vector = glove_vectors['easy']\n",
    "# see the shape of the vector (300,)\n",
    "vector.shape\n",
    "# Processing sentences is not as simple as with Spacy:\n",
    "vectors = [glove_vectors[x] for x in \"new york senate is insane\".split(' ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca157b",
   "metadata": {},
   "source": [
    "### Term2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "924f50cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in finding token\n",
      "Error in finding token\n",
      "Error in finding token\n",
      "Error in finding token\n",
      "Error in finding token\n",
      "Error in finding token\n",
      "Error in finding token\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"When the New York State Senate voted to legalize abortion in 1970, 12 Republican senators voted in favor of it\",\n",
    "            \"Gas prices have decreased to their pre-Russian invasion of Ukraine levels\",\n",
    "             \"Wisconsin's archaic abortion ban is older than 20 states\",\n",
    "             \"The USA has a gun homicide rate 26 times higher than our peers.\",\n",
    "             \"86% of Americans and 82% of gun owners support requiring all gun buyers to pass a background check\",\n",
    "             \"Joe Biden’s $36 billion for a union pension fund is the largest private pension bailout in American history\",\n",
    "             \"Biden says he released 22 years of my tax returns but Donald Trump hasn’t released a single one\"]\n",
    "             \n",
    "\n",
    "vectors = []\n",
    "for sentence in sentences:\n",
    "    words = sentence.split(\" \")\n",
    "    words = [word.lower() for word in words]\n",
    "    try:\n",
    "        vector = [glove_vectors[x] for x in words]\n",
    "        vectors.append(vector)\n",
    "    except:\n",
    "        print(f'Error in finding token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79ef77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in d:\n",
    "    l = line.strip('\\n')\n",
    "    vals = l.split(\" \")\n",
    "    term2vec[vals[0]] = np.asfarray(vals[1:])\n",
    "\n",
    "    \n",
    "for sentence in sentences:\n",
    "    words = sentence.split(\" \")\n",
    "    v = [term2vec[word] for word in words]\n",
    "    vd = [sp.euclidean(v1,v2) for v1, v2 in zip(v,v[1:])]\n",
    "    print(sentence, np.std(vd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9436d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    for paragraph in (row['clean_text'].split(' ')):\n",
    "        v = (term2vec[word] for word in paragraph)\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b45a41",
   "metadata": {},
   "source": [
    "### S-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3e29338",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eotenen/mambaforge/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#Our sentences we like to encode\n",
    "sentences = [\"When the New York State Senate voted to legalize abortion in 1970, 12 Republican senators voted in favor of it\"]\n",
    "\n",
    "\n",
    "def sim_calculator(sentences):\n",
    "    similarities = []\n",
    "    embeddings = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        words = sentence.split()\n",
    "        words = [word.lower() for word in words]\n",
    "        #print(words)\n",
    "\n",
    "        embedding = model.encode(words)\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30aebf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = sim_calculator(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0d0946b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2b32715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRYING AND HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d70a9ece",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [util\u001b[38;5;241m.\u001b[39mcos_sim(e1,e2) \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(embeddings[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],embeddings[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m:])]\n",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [\u001b[43mutil\u001b[49m\u001b[38;5;241m.\u001b[39mcos_sim(e1,e2) \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(embeddings[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],embeddings[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m:])]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'util' is not defined"
     ]
    }
   ],
   "source": [
    "[util.cos_sim(e1,e2) for e1, e2 in zip(embeddings[0][0],embeddings[0][1:])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14171ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings)\n",
    "sim = [util.cos_sim(e1,e2) for e1, e2 in zip(embeddings,embeddings[1:])]\n",
    "mean = torch.mean(torch.stack(sim))\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2920ce49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.02438809,  0.00035644,  0.02360098, ...,  0.03700326,\n",
       "         -0.06691141,  0.01926723],\n",
       "        [ 0.03733037,  0.0511618 , -0.00030604, ...,  0.06126916,\n",
       "          0.06081468,  0.04928033],\n",
       "        [ 0.00076719,  0.01072861,  0.01950581, ..., -0.01082846,\n",
       "          0.06935582, -0.01736863],\n",
       "        [-0.02547085, -0.02695013, -0.00880181, ..., -0.02022799,\n",
       "          0.1713459 , -0.03877466]], dtype=float32),\n",
       " array([[-0.07408568,  0.00926614,  0.03269223, ...,  0.02666071,\n",
       "          0.01889951, -0.08238821],\n",
       "        [ 0.00781205,  0.00412357,  0.00737377, ..., -0.03441425,\n",
       "         -0.06103116,  0.048816  ],\n",
       "        [-0.02195791,  0.04292493, -0.04130689, ...,  0.12667814,\n",
       "          0.04988158,  0.01570064],\n",
       "        ...,\n",
       "        [-0.02195791,  0.04292493, -0.04130689, ...,  0.12667814,\n",
       "          0.04988158,  0.01570064],\n",
       "        [-0.02627855,  0.08373255,  0.05348607, ...,  0.04548851,\n",
       "         -0.01260481,  0.00908799],\n",
       "        [ 0.01683358,  0.03489308, -0.01980388, ..., -0.08702169,\n",
       "          0.04442194,  0.01803971]], dtype=float32)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "sentences = [\"When the New York State Senate voted to legalize abortion in 1970, 12 Republican senators voted in favor of it\",\n",
    "            \"Gas prices have decreased to their pre-Russian invasion of Ukraine levels\",\n",
    "             \"Wisconsin's archaic abortion ban is older than 20 states\",\n",
    "             \"The USA has a gun homicide rate 26 times higher than our peers.\",\n",
    "             \"86% of Americans and 82% of gun owners support requiring all gun buyers to pass a background check\",\n",
    "             \"Joe Biden’s $36 billion for a union pension fund is the largest private pension bailout in American history\",\n",
    "             \"Biden says he released 22 years of my tax returns but Donald Trump hasn’t released a single one\"]\n",
    "  \n",
    "my = ['my cat drink milk',\n",
    "     'i jump to dog to paint scream']\n",
    "\n",
    "sim_calculator(my)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3ab3be0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input vector should be 1-D.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 17\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#Print the embeddings\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m words, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(words, embeddings):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#print(\"Words:\", words)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#print(\"Embedding:\", embedding)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     vd \u001b[38;5;241m=\u001b[39m [sp\u001b[38;5;241m.\u001b[39meuclidean(v1,v2) \u001b[38;5;28;01mfor\u001b[39;00m v1, v2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(embedding,embedding[\u001b[38;5;241m1\u001b[39m:])]\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(vd)\n",
      "Cell \u001b[0;32mIn[52], line 17\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#Print the embeddings\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m words, embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(words, embeddings):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#print(\"Words:\", words)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#print(\"Embedding:\", embedding)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     vd \u001b[38;5;241m=\u001b[39m [\u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meuclidean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mv2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v1, v2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(embedding,embedding[\u001b[38;5;241m1\u001b[39m:])]\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(vd)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/scipy/spatial/distance.py:520\u001b[0m, in \u001b[0;36meuclidean\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meuclidean\u001b[39m(u, v, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    485\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03m    Computes the Euclidean distance between two 1-D arrays.\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mminkowski\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/scipy/spatial/distance.py:463\u001b[0m, in \u001b[0;36mminkowski\u001b[0;34m(u, v, p, w)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminkowski\u001b[39m(u, v, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    414\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;124;03m    Compute the Minkowski distance between two 1-D arrays.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    461\u001b[0m \n\u001b[1;32m    462\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 463\u001b[0m     u \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_vector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     v \u001b[38;5;241m=\u001b[39m _validate_vector(v)\n\u001b[1;32m    465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/scipy/spatial/distance.py:302\u001b[0m, in \u001b[0;36m_validate_vector\u001b[0;34m(u, dtype)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m u\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m u\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput vector should be 1-D.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Input vector should be 1-D."
     ]
    }
   ],
   "source": [
    "sentences = [\"When the New York State Senate voted to legalize abortion in 1970, 12 Republican senators voted in favor of it\"]\n",
    "\n",
    "\n",
    "for sentence in sentences:\n",
    "    # Tokenize the sentence into a list of words\n",
    "    words = sentence.split()\n",
    "    words = [word.lower() for word in words]\n",
    "    \n",
    "    #Sentences are encoded by calling model.encode()\n",
    "    embeddings = model.encode(words)\n",
    "\n",
    "#Print the embeddings\n",
    "for words, embedding in zip(words, embeddings):\n",
    "    #print(\"Words:\", words)\n",
    "    #print(\"Embedding:\", embedding)\n",
    "\n",
    "    vd = [sp.euclidean(v1,v2) for v1, v2 in zip(embedding,embedding[1:])]\n",
    "    print(vd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ad5b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = gensim.downloader.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "077b378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Load pre-trained Word2Vec model\n",
    "# Example sentence\n",
    "sentences = [\"When the New York State Senate voted to legalize abortion in 1970, 12 Republican senators voted in favor of it\",\n",
    "            \"Gas prices have decreased to their pre-Russian invasion of Ukraine levels\",\n",
    "             \"Wisconsin's archaic abortion ban is older than 20 states\",\n",
    "             \"The USA has a gun homicide rate 26 times higher than our peers.\",\n",
    "             \"86% of Americans and 82% of gun owners support requiring all gun buyers to pass a background check\",\n",
    "             \"Joe Biden’s $36 billion for a union pension fund is the largest private pension bailout in American history\",\n",
    "             \"Biden says he released 22 years of my tax returns but Donald Trump hasn’t released a single one\"]\n",
    "\n",
    "for sentence in sentences:\n",
    "    # Tokenize the sentence into a list of words\n",
    "    words = sentence.split()\n",
    "    words = [word.lower() for word in words]\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Calculate similarities between all pairs of words\n",
    "    try:\n",
    "        similarities = []\n",
    "        sim_num = []\n",
    "        for i in range(len(words)):\n",
    "            for j in range(i+1, len(words)):\n",
    "                similarity = model.similarity(words[i], words[j])\n",
    "                similarities.append((words[i], words[j], similarity))\n",
    "                sim_num.append(similarity)\n",
    "                for similarity in similarities:\n",
    "                    print(similarities)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    # Print the similarity scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ba64250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Load pre-trained Word2Vec model\n",
    "# Example sentence\n",
    "def similarity_calculation(sentences):\n",
    "    for words in sentences:\n",
    "        # Tokenize the sentence into a list of words\n",
    "        words = words.split()\n",
    "        words = [word.lower() for word in words]\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        # Calculate similarities between all pairs of words\n",
    "        try:\n",
    "            similarities = []\n",
    "            sim_num = []\n",
    "            for i in range(len(words)):\n",
    "                for j in range(i+1, len(words)):\n",
    "                    similarity = model.similarity(words[i], words[j])\n",
    "                    similarities.append((words[i], words[j], similarity))\n",
    "                    sim_num.append(similarity)\n",
    "                    for similarity in similarities:\n",
    "                        print(similarity)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    return (sim_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ddb6d2b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SentenceTransformer' object has no attribute 'similarity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mege\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeniz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SentenceTransformer' object has no attribute 'similarity'"
     ]
    }
   ],
   "source": [
    "model.similarity('ege','deniz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8ef4182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "similarities_list=[]\n",
    "\n",
    "for index, sentence in enumerate(df.text):\n",
    "    # Tokenize the sentence into a list of words\n",
    "    words = sentence.split()\n",
    "    words = [word.lower() for word in words]\n",
    "    try:\n",
    "        similarities = []\n",
    "        for i in range(len(words)):\n",
    "            for j in range(i+1, len(words)):\n",
    "                similarity = model.similarity(words[i], words[j])\n",
    "                similarities.append((words[i], words[j], similarity))\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b674b550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "similarities_list = []\n",
    "for index, sentence in enumerate(df.text):\n",
    "    # Tokenize the sentence into a list of words\n",
    "    words = sentence.split()\n",
    "    words = [word.lower() for word in words]\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Calculate similarities between all pairs of words\n",
    "    try:\n",
    "        similarities = []\n",
    "        for i in range(len(words)):\n",
    "            for j in range(i+1, len(words)):\n",
    "                similarity = model.similarity(words[i], words[j])\n",
    "                similarities.append((words[i], words[j], similarity))\n",
    "                similarities_list.append(similarities)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "print(similarities_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "631a0c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: []}\n",
      "{1: []}\n",
      "{2: []}\n",
      "{3: []}\n",
      "{4: []}\n",
      "{5: []}\n",
      "{6: []}\n",
      "{7: []}\n",
      "{8: []}\n",
      "{9: []}\n",
      "{10: []}\n",
      "{11: []}\n",
      "{12: []}\n",
      "{13: []}\n",
      "{14: []}\n",
      "{15: []}\n",
      "{16: []}\n",
      "{17: []}\n",
      "{18: []}\n",
      "{19: []}\n",
      "{20: []}\n",
      "{21: []}\n",
      "{22: []}\n",
      "{23: []}\n",
      "{24: []}\n",
      "{25: []}\n",
      "{26: []}\n",
      "{27: []}\n"
     ]
    }
   ],
   "source": [
    "for index, sentence in enumerate(df.text):\n",
    "    # Tokenize the sentence into a list of words\n",
    "    words = sentence[1].split()\n",
    "    words = [word.lower() for word in words]\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Calculate similarities between all pairs of words\n",
    "    try:\n",
    "        similarities = []\n",
    "        sim_num = []\n",
    "        for i in range(len(words)):\n",
    "            for j in range(i+1, len(words)):\n",
    "                similarity = model.similarity(words[i], words[j])\n",
    "                similarities.append((words[i], words[j], similarity))\n",
    "                sim_num.append(similarity)\n",
    "                for similarity in similarities:\n",
    "                    print(similarity)\n",
    "                    \n",
    "        my_dictionary = {}\n",
    "        my_dictionary[index] = sim_num\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "    print(my_dictionary)\n",
    "    \n",
    "## I could not store them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67f0d45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
